## Fit a linear model with a, b as parameters
|x|x_1|x_2|x_n|
|y|y_1|y_2|y_n|

The vertical differences between $P_i (x_i, y_i)$ and L is:
$$|y_i-f(x_i) = |y_i-ax_i-b|$$

This makes the absolute deviations:
$$y_i-f(x_i)-residuals$$

The line L which is closest to all (x_i,y_i) i = 1,2,...n could be found
* L (or a, b) minimize the sum of absolute deviations
* L (or a, b) minimizes the largest absolute deviations

$$P_1 (x_1, y_1)$$
$$Q_1 (x_1, ax_1+b)$$

Which makes the difference between the two:

$$= \sqrt{(x_1-x_1)^2+(y_1-ax_1-b)^2}$$
$$\text{or}$$
$$=|y_1-ax_1-b|$$
- ## Fitting nonlinear models y=f(x) where f(x) is a nonlinear function.
  Consider $y=Ce^x$ with data, and we pretend that x is actually $e^x$,
  |**x**|**1**|**2**|**3**|**4**|
  |$e^x$|$e^1=2.7$|$e^2=7.4$|$e^3=20.1$|$e^4=54.6$|
  |y|8.1|22.1|60.1|165|
  
  Now, we can take any point $(x_1,y_1)$, for instance, $(2.7, 8.1)$ and obtain C, thanks to us making x nonlinear! In this case, it would come out to be $C=\frac{8.1}{2.7}=3$
  
  Alternatively, we could alter y, making it $y = ln(y).$
  |**x**|**1**|**2**|**3**|**4**|
  |ln(y)|2.1|3.1|4.1|5.1|